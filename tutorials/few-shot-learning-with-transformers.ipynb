{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdaL/ASlfpAswyiU6Tpknt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shea-Fyffe/transforming-personality-scales/blob/main/tutorials/few-shot-learning-with-transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ZVjSGx2hzd"
      },
      "source": [
        "---\n",
        "# Few-Shot Learing with Transformers (GPT-3)\n",
        "---\n",
        "\n",
        "This code is written in **Python** as an illustration of *few-shot* learning, which occurs when few labeled training examples are available (see [Ruder, 2017](https://ruder.io/transfer-learning/)). When taking a standard approach to text classification with few labeled examples, transformer architectures commonly used for text classification (e.g., *BERT*; [Devlin et al., 2019](https://arxiv.org/abs/1810.04805)) suffer inconsistent performance ([Zhang et al., 2021](http://arxiv.org/abs/2006.05987)). To overcome this researchers may choose to \"freeze\" encoder layers (e.g., [Chronopoulou et al., 2019](https://doi.org/10.18653/v1/N19-1213)); however, merely reframing the a classification task to better align with a transformer's source task seems to be a more viable option ([Brown et al., 2020](https://arxiv.org/abs/2005.14165)).\n",
        "\n",
        "By reframing a classification task into a *language modeling* task, transformers seem to better cope with a small number of training examples (e.g., [Chronopoulou et al., 2019](https://doi.org/10.18653/v1/N19-1213); [Schick & Schütze, 2021](https://arxiv.org/abs/2009.07118)). In a language modeling task, a model is trained to predict the next word in a sequence of words; this task is somewhat universal when it comes to pretraining a transformer model, so much so that it allows large decoder models (e.g., *GPT-3*; [Brown et al., 2020](https://arxiv.org/abs/2005.14165)), which are most often used for language generation tasks, to perform text classification tasks. We demonstrate this approach by using GPT-3 to perform few-shot classification. We provide a baseline by comparing this approach to a standard approach to test classification.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Things to Remember before Beginning\n",
        "- You will need to register for an API key on OpenAI's website [here](https://beta.openai.com/). There are also several open source versions available; however, they've yet to achieve GPT-3's level of performance.\n",
        "- We recommend only using the method illustrated here when researchers have **fewer than 40 examples per label.** Given how GPT-3's *Completions API* works, this method can become quite expensive for those with little $$ to their names (e.g., poor graduate students like me). For those with more than 40 examples (or even 20) but less than 100, it may be worth it to use a *fine-tuning* approach with GPT-3. Read more about that approach [here](https://platform.openai.com/docs/guides/fine-tuning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPlCRN53ULva"
      },
      "source": [
        "### Libraries\n",
        "\n",
        "Colab comes with a large number of Python libraries pre-installed. However, `openai` and `transformers` are not libraries pre-installed libraries, however, these library can be installed by using the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7S6aRPS_w63"
      },
      "source": [
        "#@title RUN: Installing OpenAI and Transformer Libraries\n",
        "%%capture\n",
        "! pip install openai\n",
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A25eSs8QUkS8"
      },
      "source": [
        "#@title RUN: Loading Libraries\n",
        "# GPT3 related libraries\n",
        "import openai\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# Data management libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from google.colab import drive # optional for getting data\n",
        "\n",
        "# General utility libraries\n",
        "import os\n",
        "import sys\n",
        "import time # for sleeping between requests\n",
        "import requests # for downloading url\n",
        "from io import StringIO # for downloading data from url\n",
        "from typing import Dict, List, Union # for type hinting\n",
        "from sklearn.metrics import classification_report # for model evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mounting Google Drive\n",
        "It is often a good idea to allow Colab to mount (or connect) to your Google Drive. This allows you to easily save models or—as we demonstrate—import data. By default, Colab's working directory is `/content/`, we can place our Google Drive root directory within this folder. If you've changed your current working directory, you can use `os.getcwd()` to see your current directory"
      ],
      "metadata": {
        "id": "A2ounVPbGmVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RUN: Connect to Drive *Optional*\n",
        "# Connect the current working directory to a user's Google Drive account\n",
        "drive.mount(os.getcwd() + '/drive')"
      ],
      "metadata": {
        "id": "va9W9UqUGYL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bc4bac-ae6c-4628-bad8-bfc2308da41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKw_ddT8-0Jz"
      },
      "source": [
        "## Classes and Functions\n",
        "\n",
        "Here we define a class and several class functions that will be used to train and extract classifications from an instance of `GPT-3`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN: Model Class\n",
        "class FewShotGPT3:\n",
        "    \"\"\"\n",
        "    A Few-shot learning class for the transformer GPT-3\n",
        "    \"\"\"\n",
        "    def __init__(self, data, api_token: str, model: str = 'davinci', max_token_length = 2048, instruction_template = None, context_template_function = None):\n",
        "        \"\"\"\n",
        "        Initializing few shot model.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        data: a Pandas DataFrame with text and labels that will be used for training.\n",
        "        api_key: a string representing API token from beta.openai.com\n",
        "        model: a string of GPT-3 model to be used (e.g., ada, babbage, curie, davinci) ('davinci' by default).\n",
        "        max_token_length: a number representing the max token length of the model (2048 by default).\n",
        "        instruction_template_function: a string to be used as instruction in the prompt (if None by will auto generate based on labels).\n",
        "        context_template_function: a function to be used to form few shot context string (None by default).\n",
        "\n",
        "\n",
        "        \"\"\"    \n",
        "        def default_instruction_template_fn(x: List[str]) -> str:\n",
        "            \"\"\"\n",
        "             Default instruction template function.\n",
        "            \"\"\"\n",
        "            instruction = f\"Please classify a piece of text into the following categories: {', '.join(x)}.\"\n",
        "            return f\"{instruction.strip()}\\n\\n\"\n",
        "\n",
        "        def default_context_template_fn(text, labels = None) -> str:\n",
        "            \"\"\"\n",
        "            Default context template function. \n",
        "            \n",
        "            Used for example query as well.\n",
        "            \"\"\"\n",
        "            if labels is None:\n",
        "                text = text.replace(\"\\n\", \" \").strip()\n",
        "                return f\"Text: {text}\\nCategory:\"\n",
        "            context = []\n",
        "            for ti, li in zip(text, labels):\n",
        "                context.append(\"Text: {text}\\nCategory: {label}\\n---\\n\".format(\n",
        "                    text=ti.replace(\"\\n\", \" \").strip(),\n",
        "                    label=li.replace(\"\\n\", \" \").strip(),\n",
        "                ))\n",
        "            return \"\".join(context)\n",
        "\n",
        "        openai.api_key = os.environ[\"OPENAI_API_KEY\"] = self.api_key = api_token\n",
        "        self.model = model\n",
        "        self.tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "        self.max_token_len = max_token_length\n",
        "        \n",
        "        self.raw_results = []\n",
        "        self.raw_prediction_results = []\n",
        "\n",
        "        data[data.columns[1]] = self.format_labels(data[data.columns[1]])\n",
        "        self.training_data = data\n",
        "        self.instruction_template = instruction_template if instruction_template is not None else default_instruction_template_fn(list(self.label_to_index.values()))\n",
        "        self.context_template_fn = context_template_function if context_template_function is not None else default_context_template_fn\n",
        "\n",
        "\n",
        "    def __str__(self, verbose = False):\n",
        "        \"\"\"\n",
        "        Custom print method \n",
        "        \"\"\"\n",
        "        if verbose:\n",
        "            return str(self.__class__) + '\\n'+ '\\n'.join(('{} = {}'.format(item, self.__dict__[item]) for item in self.__dict__))\n",
        "\n",
        "        print_res = \"GPT-3 architecture: %s\\nTraining data imported: %s\\n\" % (self.model, hasattr(self, \"training_data\"))\n",
        "        if hasattr(self, \"training_data\"):\n",
        "            label_str = [k + \"(\" + v + \")\" for k, v in self.label_to_index.items()]\n",
        "            print_res = print_res + \"Training data size: %d\\nText col: %s\\nLabel col: %s\\nLabel Mapping:\\n%s\" % (len(self.training_data),\n",
        "                                                                                                              self.training_data.columns[0], \n",
        "                                                                                                              self.training_data.columns[1],\n",
        "                                                                                                              '\\n'.join(label_str))\n",
        "        return print_res\n",
        "    \n",
        "    def format_labels(self, labels: List[str], ignore_case: bool = True, sort: bool = True) -> List[str]:\n",
        "        \"\"\"\n",
        "        Format and tokenize labels.\n",
        "\n",
        "        This function will always map labels to a single number (e.g., 0, 1, 2, 3, and so forth) \n",
        "        \n",
        "        Arguments\n",
        "        ---------\n",
        "        labels: a list of labels\n",
        "        ignore_case: a boolean flag to treat labels as case-insensitive (optional, default: True)\n",
        "        sort: a boolean specifying if labels should be sorted alphabetically before recoding (optional, default: True)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[str]\n",
        "            a list of labels mapped to integer strings.\n",
        "        Dict[str:str]\n",
        "            a map of original labels and new label.\n",
        "        Dict[str:int]\n",
        "            a map of new labels and their GPT-3 token id.\n",
        "        \"\"\"\n",
        "        labels = [label.replace(\"\\n\", \" \").strip() for label in labels]  \n",
        "        if ignore_case:\n",
        "            labels = [label.lower() for label in labels]  \n",
        "        unique_labels = list(set(labels))\n",
        "        if sort:\n",
        "            unique_labels.sort()\n",
        "        label_to_index = {k: str(i) for i, k in enumerate(unique_labels)}\n",
        "        index_to_label = {str(i): k for i, k in enumerate(unique_labels)}\n",
        "        token_to_index = {self.tokenizer.encode(\" \" + str(i))[0]: str(i) for i, _ in enumerate(unique_labels)}\n",
        "        \n",
        "        labels_out = []\n",
        "        for j in labels:\n",
        "            labels_out.append(label_to_index[j])\n",
        "        self.label_to_index = label_to_index\n",
        "        self.index_to_label = index_to_label\n",
        "        self.token_to_index = token_to_index\n",
        "        self.num_labels = len(label_to_index)\n",
        "        \n",
        "        return labels_out\n",
        "\n",
        "    def build_prompt(self, query_doc: str, add__instructions: bool = True) -> str:\n",
        "        \"\"\"\n",
        "        Internal method for building prompt.\n",
        "\n",
        "        Arguments\n",
        "        --------- \n",
        "        add__instructions: a boolean determining whether to add instructions to the prompt before prediction (True by default).\n",
        "\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"few_shot_data\"):\n",
        "           raise AttributeError(\"Few shot examples have not been selected. Use `select_few_shot()` before proceeding.\")\n",
        "        instructions = self.instruction_template if add__instructions else \"\"\n",
        "        context = self.context_template_fn(self.few_shot_data[self.few_shot_data.columns[0]],\n",
        "                                           self.few_shot_data[self.few_shot_data.columns[1]])\n",
        "        query = self.context_template_fn(query_doc)\n",
        "        prompt = instructions + context + query\n",
        "        n_total_tokens = len(self.tokenizer.encode(prompt))\n",
        "        if n_total_tokens > self.max_token_len:\n",
        "            raise Exception(\n",
        "                user_message=f\"The prompt contains {n_total_tokens} tokens, which is above the {self.max_token_len} token limit.\"\n",
        "                f\"Please consider setting add_instructions = False, selecting fewer few shot examples (by using select_few_shot()),\"\n",
        "                \"or changing the context_template_fn.\"\n",
        "            )\n",
        "        return prompt  \n",
        "\n",
        "\n",
        "    def select_few_shot(self, few_shot_k: int = 1,  select_indices: List[int] = None, seed: int = 42, shuffle = True):\n",
        "        \"\"\"\n",
        "        Method to select (i.e., subsample) training examples for few shot classification.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        few_shot_k: a number of random examples per class to select for few shot learning (1 by default).\n",
        "        select_indices: an optional list of numeric indices in training data for few shot examples to be used instead of random sampling from training data (None by default).\n",
        "        seed: a number of random seed for sub-sampling a few examples (k) (42 by default).\n",
        "        shuffle: a boolean to shuffle rows in data using random seed (True by default).\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"training_data\"):\n",
        "           raise AttributeError(\"Training data not yet loaded. Use `import_training_data()` before proceeding.\")\n",
        "        \n",
        "        few_shot_data = self.training_data\n",
        "        \n",
        "        if select_indices is not None:\n",
        "            # add 1 to index to make it more intuitive\n",
        "            few_shot_data = few_shot_data.iloc[[i+1 for i in select_indices if select_indices <= len(self.training_data)]]\n",
        "        else:\n",
        "            few_shot_data = few_shot_data.groupby(few_shot_data.columns[1], group_keys=False).apply(lambda x: x.sample(n=int(few_shot_k), random_state = seed))\n",
        "        \n",
        "        if shuffle:\n",
        "            few_shot_data = few_shot_data.sample(frac=1, random_state = seed).reset_index(drop=True)\n",
        "\n",
        "        self.few_shot_data = few_shot_data\n",
        "        return print('Few shot examples selected successfully.')\n",
        "\n",
        "\n",
        "    def predict(self, test: List[str], request_delay: int = 1, **kwargs):\n",
        "        \"\"\"\n",
        "        Method to predict labels of unlabelled text documents.\n",
        "        \n",
        "        Arguments\n",
        "        ---------\n",
        "        test: a list of text documents to be predicted (imported via `import_test_data()` by default)\n",
        "        request_delay: a number determining the time (in seconds) to wait between calls to API (1 by default).\n",
        "        kwargs: additional keyword arguments to pass to `openai.Completion.create()`\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            a dictionary of raw prediction data.\n",
        "        \"\"\"\n",
        "        \n",
        "        # reinitialize results every prediction\n",
        "        self.raw_results = []\n",
        "        self.prediction_results = []\n",
        "\n",
        "        default_kwargs = {\n",
        "            \"engine\": self.model,\n",
        "            \"temperature\": 0.0,\n",
        "            \"logprobs\": self.num_labels,\n",
        "            \"max_tokens\": 1,\n",
        "        }\n",
        "\n",
        "        completion_args = { **default_kwargs, **kwargs }\n",
        "\n",
        "        for test_doc in test:\n",
        "            time.sleep(request_delay)\n",
        "            err_message = {}\n",
        "            completion_args['prompt'] = self.build_prompt(test_doc)\n",
        "            try:\n",
        "                completion_resp  = openai.Completion.create(**completion_args)\n",
        "            except TypeError as err:\n",
        "                err_message = {\n",
        "                    'plain language message':'A test document may be blank or a number.\\n' +\n",
        "                                             'See error message below...\\n===\\n',\n",
        "                    'error message': err,\n",
        "                    'error class': err.__class__,\n",
        "                }\n",
        "            except openai.error.InvalidRequestError as err:\n",
        "                err_message = {\n",
        "                    'plain language message':'API Request to OpenAI was invalid.\\n' +\n",
        "                                             'May result from issue with API key or model id.\\n' +\n",
        "                                             'See error message below...\\n===\\n',\n",
        "                    'error message': err,\n",
        "                    'error class': err.__class__,\n",
        "                }\n",
        "            except openai.error.RateLimitError as err:\n",
        "                err_message = {\n",
        "                    'plain language message':'API Requests are being made too fast!\\n' +\n",
        "                                            'Please increase the request_delay argument and try again.\\n' +\n",
        "                                            'See error message below...\\n===\\n',\n",
        "                    'error message': err,\n",
        "                    'error class': err.__class__,\n",
        "                }\n",
        "            except Exception as err:\n",
        "                err_message = {\n",
        "                    'plain language message':'Some other error occurred.\\n' +\n",
        "                                             'See error message below...\\n===\\n',\n",
        "                    'error message': err,\n",
        "                    'error class': err.__class__,\n",
        "                }\n",
        "            if err_message:\n",
        "                for key,value in err_message.items():\n",
        "                    print(key, \":\", value)\n",
        "                print(\"Attempting to return partial data...\")\n",
        "                return self.raw_results\n",
        "            \n",
        "            self.raw_results.append(completion_resp)\n",
        "            preds = self.extract_prediction(completion_resp)\n",
        "            preds['text'] = test_doc\n",
        "            self.prediction_results.append(preds)\n",
        "        return print(\"Predictions complete! Please see <model>.prediction_results\")\n",
        "\n",
        "\n",
        "    def extract_prediction(self, x):\n",
        "        \"\"\"\n",
        "        Internal method for extracting predictionss from GPT-3 Completion API\n",
        "        \"\"\" \n",
        "        xi = x['choices'][0]['logprobs']['top_logprobs'][0]\n",
        "        token_probs = defaultdict(float, {k: float() for k in self.token_to_index.keys()})\n",
        "        for token, logp in sorted(xi.items()):\n",
        "            token_probs[self.tokenizer.encode(token)[0]] += np.exp(logp)\n",
        "        label_probs = {\n",
        "            self.index_to_label[self.token_to_index[token]]: prob for token, prob in token_probs.items()\n",
        "            if token in self.token_to_index.keys()\n",
        "        }\n",
        "        # Fill in the probability for the special 'unknown_label_p' label--which are predictions that weren't specified \n",
        "        label_probs['unknown_label_p'] = 0.0\n",
        "        if sum(label_probs.values()) < 1.0:\n",
        "            label_probs['unknown_label_p'] = 1.0 - sum(label_probs.values())\n",
        "        label_probs[\"predicted_label\"] = max(label_probs, key=label_probs.get)\n",
        "        return label_probs\n",
        "\n",
        "\n",
        "    def output_predictions(self, output_file: bool = False, output_file_name: str = \"prediction-results.csv\"):\n",
        "        \"\"\"\n",
        "        Internal method to output test predictions to a csv file.\n",
        "        \n",
        "        Arguments\n",
        "        ---------\n",
        "        output_file: a boolean specifying results should be written to a .csv file (False by default).\n",
        "        output_file_name: a string of a csv file path to write predictions to ('prediction-results.csv' by default).\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            A dataframe of prediction data.\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"prediction_results\"):\n",
        "           raise AttributeError(\"Predictions not yet created. Use `predict()` before proceeding.\")\n",
        "        out_data = pd.DataFrame(self.prediction_results)\n",
        "        col = out_data.pop('text')\n",
        "        out_data.insert(0, col.name, col)\n",
        "        if output_file:\n",
        "            out_data.to_csv(output_file_name, index=False)\n",
        "            return print(f\"file output to: {output_file_name}\")\n",
        "        return out_data"
      ],
      "metadata": {
        "id": "WoDYi6OTBGAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN: Helper Functions\n",
        "\n",
        "# import data\n",
        "def import_data(csv_path: str, text_col: str = \"text\", label_col: str = \"label\",  enc: str = 'latin1', sort_labels: bool = True):\n",
        "    \"\"\"\n",
        "    Function to import a csv of text documents with labels for few shot training.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    csv_path: a string identifying the csv file path (or url).\n",
        "    text_col: a string of the column name in csv containing text documents ('text' by default).\n",
        "    label_col: a string of the column name containing labels ('label' by default).\n",
        "    enc: File encoding to be used  ('latin1' by default).\n",
        "    shuffle: shuffle rows in data (True by default).\n",
        "    seed: Random seed for shuffling data (42 by default).\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        A dataframe of text and labels (unless label_col is None).\n",
        "    \"\"\"\n",
        "    if (csv_path.startswith(\"http\")):\n",
        "        res = requests.get(csv_path,\n",
        "                           headers= {'User-Agent': 'Mozilla/5.0',\n",
        "                                     \"X-Requested-With\": \"XMLHttpRequest\"})\n",
        "        csv_path = StringIO(res.text)\n",
        "    df = pd.read_csv(csv_path, encoding = enc)\n",
        "    subset_cols = [text_col]\n",
        "    if label_col is not None:\n",
        "         subset_cols.append(label_col)\n",
        "    return df[subset_cols]\n",
        "\n",
        "# get api key\n",
        "def get_api_key(file_path: str = \"/content/drive/MyDrive/Colab Notebooks/docs/gpt-3-api-key.txt\"):\n",
        "    \"\"\"\n",
        "    Helper function to retreive OpenAI api key from txt file.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    file_path: a string identifying txt file storing an OPENAI API key.\n",
        "\n",
        "    \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        f = open(file_path)\n",
        "        return f.readline().strip()\n",
        "    return \"\"\n",
        "\n",
        "# Compute evaluation metrics\n",
        "def evaluate_model(actual: List[str], predicted: List[str], label_values = None, **kwargs):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics on test data (given labels are available).\n",
        "\n",
        "    A helper function that returns model evaluation metrics. \n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    actual: list of actual labels.\n",
        "    predicted: list of predicted labels.\n",
        "    label_values: a list of *unique ordered* labels (derives from actual labels by default).\n",
        "    kwargs: additional keyword arguments to pass to ``sklearn.metrics.classification_report()``.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "      summary of the precision, recall, F1 score for each class\n",
        "    \"\"\"\n",
        "    if label_values is not None:\n",
        "        kwargs.update({'target_names': label_values})\n",
        "    else:\n",
        "        kwargs.update({'target_names': list(set(actual))})\n",
        "        \n",
        "    res = classification_report(y_true = actual, y_pred = predicted, output_dict = True, **kwargs)\n",
        "\n",
        "    class_level = {k: res.get(k, None) for k in res.keys() if k in kwargs['target_names']}\n",
        "    overall = {k: res.get(k, None)for k in res.keys() if k not in kwargs['target_names']}\n",
        "    return {'overall' : pd.DataFrame(overall), 'by_label': pd.DataFrame(class_level)}"
      ],
      "metadata": {
        "id": "UVM5nsuPnqKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Defining Parameters\n",
        "---"
      ],
      "metadata": {
        "id": "uhqWDPRc-0fO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPqexbkgUc6q"
      },
      "source": [
        "#@markdown ## RUN: Entering API Key\n",
        "# this can be stored as an environmental variable (ideal when using a local machine)\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "API_KEY = get_api_key()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHoZK4sZcatF"
      },
      "source": [
        "#@markdown ## RUN: Defining Number of Few Shot Examples\n",
        "# here, we define a global variable for the number of examples (per label) to use during training\n",
        "FEWSHOTK = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Importing and Formatting Data\n",
        "---\n",
        "There are several ways to import training data (see our [tutorial]()). Importantly, the training data should be a `csv` (or url to a csv), and can be imported using the `import_data()` function.\n",
        "\n",
        "By default, the `import_data` function assumes that the text is found in a column labeled `text` and the labels are found in the `label` column. However, this can be modified by changing the `text_col` and `label_col` arguments when calling the function.\n",
        "<br>\n",
        "\n",
        "#### Importing Training Data from Online Repository\n",
        "\n",
        "While there are several ways to import data into Colab ([see here](https://colab.research.google.com/notebooks/io.ipynb)), the most intuitive way is to use the project's code repository url:\n",
        "\n",
        "```python\n",
        "# Assign the online data repository to a url so it does not have to be repeated later\n",
        "repository_data_url = \"https://raw.githubusercontent.com/Shea-Fyffe/transforming-personality-scales/main/data/text-classification/\"\n",
        "\n",
        "training_data = import_data(repository_data_url + \"train-data.csv\", text_col = 'docs', label_col = 'labels')\n",
        "```\n",
        "<br>\n",
        "\n",
        "#### Importing Training Data from Local Repository\n",
        "\n",
        "You can also upload a local `.csv` file. You can do this by:\n",
        "- Visiting the project url above and clicking the `download file` button (top right in project repository)\n",
        "- Clicking the ***Files*** pane in Colab (the folder icon on the left in Colab)\n",
        "- Clicking the ***Upload to session storage*** icon (left-most icon in Colab)\n",
        "- Selecting the local data file you would like to use (e.g., `.csv`,`.tsv`)\n",
        "\n",
        "We demonstrate examples below.\n",
        "<br>\n",
        "\n",
        "#### Examples: Importing Data\n",
        "```python\n",
        "# If your csv file (e.g., train-data.csv) contains text data in the column 'docs' and labels in the column 'labels'\n",
        ">>> training_data = import_data(\"train-data.csv\", text_col = 'docs', label_col = 'labels')\n",
        "\n",
        "# If your csv file (e.g., my-data.csv) contains text data in the column 'text_examples' and labels in the column 'classes'\n",
        ">>> training_data = import_data(\"my-data.csv\", text_col = 'text_examples', label_col = 'classes')\n",
        "```"
      ],
      "metadata": {
        "id": "7UV3cbv63nDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #RUN: Import Training Data\n",
        "# Assign the online data repository to a url so it doesn't have to be repeated laterr\n",
        "repository_data_url = 'https://raw.githubusercontent.com/Shea-Fyffe/transforming-personality-scales/main/data/text-classification/'\n",
        "\n",
        "# Import the training data\n",
        "training_data = import_data(repository_data_url + \"train-data.csv\")\n",
        "\n",
        "# View the first several rows of the training data\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "vYmz5jdG_LWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1bdfd3ae-812a-4b11-f6ba-c11c5844944c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        text              label\n",
              "0                   I rarely feel depressed.        neuroticism\n",
              "1             I always know what I am doing.  conscientiousness\n",
              "2  I do not put my mind on the task at hand.  conscientiousness\n",
              "3                        I keep things tidy.  conscientiousness\n",
              "4                             I laugh a lot.       extraversion"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a41eb8c6-a69c-43f8-b3bf-cc63168cdf11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I rarely feel depressed.</td>\n",
              "      <td>neuroticism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I always know what I am doing.</td>\n",
              "      <td>conscientiousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I do not put my mind on the task at hand.</td>\n",
              "      <td>conscientiousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I keep things tidy.</td>\n",
              "      <td>conscientiousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I laugh a lot.</td>\n",
              "      <td>extraversion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a41eb8c6-a69c-43f8-b3bf-cc63168cdf11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a41eb8c6-a69c-43f8-b3bf-cc63168cdf11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a41eb8c6-a69c-43f8-b3bf-cc63168cdf11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU5mojBFURyy"
      },
      "source": [
        "---\n",
        "### Initializing GPT-3 Model\n",
        "---\n",
        "We've created a class `FewShotGPT3` that will serve as the model. When initially calling the class, three things will need to be defined: \n",
        "\n",
        "- `data` which is the training data (imported above using `import_data()`). The `data` argument must be a DataFrame with two columns (i.e., text documents and labels)\n",
        "- `api_token` which is your OpenAI API token ([login here to view your api token](https://openai.com/api/)). While we've stored our api token above using the `API_KEY` object, you can manually enter it when initializing the model (see examples below).\n",
        "\n",
        "There are several other arguements that can be seen by calling `print(FewShotGPT3.__init__.__doc__)`.\n",
        "<br>\n",
        "\n",
        "#### Examples: Initializing GPT-3 Model\n",
        "```python\n",
        "## Common use-case\n",
        "# To initialized a few shot model in the most common case \n",
        ">>> few_shot_model = FewShotGPT3(data = training_data, api_token = API_KEY)\n",
        "\n",
        "## Manual use-case\n",
        "# If we wanted to manually input out api key and training data\n",
        "training_data = pd.DataFrame(data =\n",
        "    {\n",
        "    'text':[\"document 1\", \"document 2\", \"document 3\", \"document 4\"],\n",
        "    'label': [\"label a\", \"label b\", \"label b\", \"label a\"],\n",
        "    })\n",
        ">>> few_shot_model = FewShotGPT3(data = training_data, api_token = 'a_fake_api_key_abc123')\n",
        "\n",
        "## Varying architectures\n",
        "# To initialized a few shot model object with 'ada' \n",
        ">>> few_shot_model = FewShotGPT3(data = training_data, api_token = API_KEY, model = 'ada')\n",
        "\n",
        "# To initialized a few shot model object with 'curie' \n",
        ">>> few_shot_model = FewShotGPT3(data = training_data, api_token = API_KEY, model = 'curie')\n",
        "\n",
        "## Additional cases\n",
        "# changing instruction text for prompt \n",
        ">>> few_shot_model = FewShotGPT3(data = training_data, api_token = API_KEY, instruction_template = \"Classify this text document.\\n\\n\")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN: Initialize Few Shot Model\n",
        "few_shot_model = FewShotGPT3(data = training_data, api_token = API_KEY)"
      ],
      "metadata": {
        "id": "4LuorG6oyC83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Inspecting Model\n",
        "---\n",
        "The `few_shot_model` object, which is an *instance* of our `FewShotGPT3` class, stores several useful things after it's been initialized. Most are automatically derived from the training data. Some of the more important attributes are:\n",
        "+ **label_to_index**: The labels identified from the training data mapped to a numeric representation or code (this is determined alphabetically be default). Thus, when classifying the Big Five, *agreeableness* = \"0\", *conscientiousness* = \"1\", *extraversion* = \"2\", and so forth. \n",
        "+ **token_to_index**: GPT *tokenizes* characters before prediction; this produces a series of position index values which represent the row of each label's numeric representation in GPT's pre-trained vocabulary. Words are often tokenized into sub-word units, which can lead to complications (especially when two different labels begin with the same tokens). Thus, we map labels to a numeric representation (e.g., \"0\",\"1\", \"2\", \"3\") to avoid this problem.\n",
        "+ **num_labels**: The number of labels identified."
      ],
      "metadata": {
        "id": "30CA2v6PztfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN: Inspect Model\n",
        "# We can get an overview of the model using the print function\n",
        "print(few_shot_model)\n",
        "\n",
        "# Look at your first tokens to verify they are unique\n",
        "few_shot_model.label_to_index"
      ],
      "metadata": {
        "id": "iMTQa44Tzsp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad1e58a-2fa5-4539-9f27-a2f36179e9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-3 architecture: davinci\n",
            "Training data imported: True\n",
            "Training data size: 733\n",
            "Text col: text\n",
            "Label col: label\n",
            "Label Mapping:\n",
            "agreeableness(0)\n",
            "conscientiousness(1)\n",
            "extraversion(2)\n",
            "neuroticism(3)\n",
            "openness(4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agreeableness': '0',\n",
              " 'conscientiousness': '1',\n",
              " 'extraversion': '2',\n",
              " 'neuroticism': '3',\n",
              " 'openness': '4'}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Selecting Few Shot Examples\n",
        "---\n",
        "Since this is an illustration of *Few-Shot* learning. We can call the `select_few_shot()` function which either: \n",
        "\n",
        "**(A)** randomly samples `few_shot_k` examples *per* label. For example, if you have five labels, setting `few_shot_k = 2` will create a few shot dataset of size 10 in your model object. Different random seeds can be used via the `seed` argument.\n",
        "\n",
        "**(B)** allows one to pick particular examples using the `select_indices` argument. For example, you would like to use the 1st, 3rd, 4th, 10th, and 15th cases in your `training data` as few shot examples you woud pass `select_indices = [1, 3, 4, 10, 15]` to the `select_few_shot()` function.\n",
        "\n",
        "We provide examples of various use cases below.\n",
        "\n",
        "#### Examples: Selecting Few Shot Examples\n",
        "```python\n",
        "## Common use-cases\n",
        "# Randomly select 1 item per label\n",
        ">>> few_shot_model.select_few_shot()\n",
        "\n",
        "# Randomly select 2 item per label\n",
        ">>> few_shot_model.select_few_shot(few_shot_k = 2)\n",
        "\n",
        "# Randomly select 5 item per label\n",
        ">>> few_shot_model.select_few_shot(5)\n",
        "\n",
        "## Manual selection of examples\n",
        "# use 5th, 9th, 20th, 30th cases in training data for few shot learning\n",
        ">>> few_shot_model.select_few_shot(select_indices = [5, 9, 20, 30])\n",
        "\n",
        "# Get every 4th case in training data for few shot learning\n",
        ">>> indx = list(range(len(few_shot_model.training_data))\n",
        ">>> fourth_indx = indx[0::4]\n",
        ">>> few_shot_model.select_few_shot(select_indices = fourth_indx)\n",
        "```"
      ],
      "metadata": {
        "id": "hGnaAkNxVqmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN:  Select Few Shot Examples\n",
        "#The select_few_shot method will update our model object by adding a few shot dataset\n",
        "few_shot_model.select_few_shot(FEWSHOTK)\n",
        "# You can check the newly created few shot dataset by typing in `.few_shot_data` after your model object\n",
        "few_shot_model.few_shot_data"
      ],
      "metadata": {
        "id": "nerQwcxmVlvF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "9114397f-873b-4f12-b0ce-f4c72714f107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few shot examples selected successfully.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text label\n",
              "0                            I make a fool of myself.     1\n",
              "1                         I feel crushed by setbacks.     3\n",
              "2                                 I show my feelings.     0\n",
              "3   Others perceive that I understand things quickly.     4\n",
              "4                                I joke around a lot.     2\n",
              "5                                I do not plan ahead.     1\n",
              "6                                 I amuse my friends.     2\n",
              "7                              I look down on others.     0\n",
              "8               I enjoy examining myself and my life.     4\n",
              "9         I want things to proceed according to plan.     1\n",
              "10  I am someone who tends to find fault with others.     0\n",
              "11        I am skilled in handling social situations.     2\n",
              "12                         I want things done my way.     3\n",
              "13                                    I trust others.     0\n",
              "14                             I love to help others.     0\n",
              "15        I carry the conversation to a higher level.     4\n",
              "16                          I cannot make up my mind.     3\n",
              "17                         I rebel against authority.     4\n",
              "18                       I barge in on conversations.     3\n",
              "19              I look for hidden meanings in things.     4\n",
              "20                I prefer to just let things happen.     1\n",
              "21   Others perceive that I like being around people.     2\n",
              "22     I am someone who is sometimes shy introverted.     2\n",
              "23                    I have a low opinion of myself.     3\n",
              "24                     I work according to a routine.     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df499e2f-ea4e-45a6-8d42-9033f6580691\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I make a fool of myself.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I feel crushed by setbacks.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I show my feelings.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Others perceive that I understand things quickly.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I joke around a lot.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I do not plan ahead.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I amuse my friends.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I look down on others.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I enjoy examining myself and my life.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I want things to proceed according to plan.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I am someone who tends to find fault with others.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I am skilled in handling social situations.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I want things done my way.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I trust others.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I love to help others.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I carry the conversation to a higher level.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>I cannot make up my mind.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I rebel against authority.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I barge in on conversations.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I look for hidden meanings in things.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>I prefer to just let things happen.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Others perceive that I like being around people.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>I am someone who is sometimes shy introverted.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>I have a low opinion of myself.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>I work according to a routine.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df499e2f-ea4e-45a6-8d42-9033f6580691')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df499e2f-ea4e-45a6-8d42-9033f6580691 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df499e2f-ea4e-45a6-8d42-9033f6580691');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Importing Testing Data\n",
        "---\n",
        "Again, we can use the repository url that was specified earlier. Since out \"test set\" is not really a test set (given labels are present), we will import the labels for model evaluation later on."
      ],
      "metadata": {
        "id": "iMBqdeMT5Ob6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN:  Import Test Data\n",
        "test_data = import_data(repository_data_url + \"test-data.csv\", label_col='label')\n",
        "# convert test text to a list for the predict function\n",
        "test_text = test_data['text'].tolist()\n",
        "# see first 5 cases\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "47XUX2fH5SPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "df7a8f4d-36f1-4999-c2f5-0eacd98c6e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  text          label\n",
              "0  I avoid imposing my will on others.  agreeableness\n",
              "1  I rarely put people under pressure.  agreeableness\n",
              "2   I am out for my own personal gain.  agreeableness\n",
              "3  I show my feelings when I am happy.   extraversion\n",
              "4         I have a strong personality.   extraversion"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2733d234-5004-46f2-91d4-b7ac7f51d621\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I avoid imposing my will on others.</td>\n",
              "      <td>agreeableness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I rarely put people under pressure.</td>\n",
              "      <td>agreeableness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am out for my own personal gain.</td>\n",
              "      <td>agreeableness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I show my feelings when I am happy.</td>\n",
              "      <td>extraversion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have a strong personality.</td>\n",
              "      <td>extraversion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2733d234-5004-46f2-91d4-b7ac7f51d621')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2733d234-5004-46f2-91d4-b7ac7f51d621 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2733d234-5004-46f2-91d4-b7ac7f51d621');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Used for Prediction\n",
        "\n",
        "By default, the `predict()` method will use the `few_shot_data` for training the model before predicting each text document passed via `predict(text = ...)`. However, if `few_shot_data` is *not* created by calling `select_few_shot()` the model will \"attempt\" to use the complete training data (this may lead to an error if all of the training examples do not fit in the prompt).\n",
        "\n",
        "Test cases can also be specifed manually via the `test` argument:\n",
        "```\n",
        "# Instead of predicting the test data, predict manually entered text\n",
        "two_new_test_docs = ['I enjoy playing group sports.', 'When getting things done, I like to boss people around.']\n",
        ">>> few_shot_model.predict(test = two_new_test_docs)\n",
        "```\n"
      ],
      "metadata": {
        "id": "r8HlAcpms7jA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Predicting Labels of Test Cases\n",
        "---\n",
        "Since both training and testing data has been loaded, we can now classify the test cases. GPT-3's *Completions API* simplifies the training process by training the model and predicting test cases concurrently. **One limitation to note**, however, is that the Completions API **may only predict one test case at a time.** Thus, the `predict()` function will loop through each test example.\n",
        "\n",
        "Additionally, with the exception of the `test` and `request_delay` arguments, the `predict()` function allows for arguments to be passed directly to `openai.Completion.create()`(i.e., the Completions API). To see a list of additional arguments, visit the [Completions API documentation](https://platform.openai.com/docs/api-reference/completions). We provide several examples below.\n",
        "\n",
        "\n",
        "#### Examples: Customizing GPT-3 Predictions\n",
        "```python\n",
        "## Common use-cases\n",
        "# import test data\n",
        ">>> test_data = import_data(\"test-data.csv\", label_col='label')\n",
        ">>> test_text = test_data['text'].tolist()\n",
        ">>> predictions = few_shot_model.predict(test = test_text)\n",
        "\n",
        "## Additional Examples\n",
        "# increasing the temperature\n",
        "#|- Not recommended (for classification), however, this could be used in cases ...\n",
        "#|- where one would like to see possible confounding labels.\n",
        ">>> few_shot_model.predict(test = test_text, temperature = 0.10)\n",
        "\n",
        "# Use a different version of Davinci\n",
        ">>> few_shot_model.predict(test = test_text, model = 'davinci-instruct-beta')\n",
        "\n",
        "# Have model return only top predicted label\n",
        ">>> few_shot_model.predict(test = test_text, logprobs = 1)\n",
        "```"
      ],
      "metadata": {
        "id": "IQKzs4Wz7DKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Predictions\n",
        "We will now run the predict method."
      ],
      "metadata": {
        "id": "afMTkmw8vnlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN:  Predict Test Cases\n",
        "few_shot_model.predict(test_text)"
      ],
      "metadata": {
        "id": "IU4qjCW1O7tp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46f6611-85aa-40a9-ef94-60984f429b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions complete! Please see <model>.prediction_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Inspecting and Outputting Predictions\n",
        "---\n",
        "\n",
        "#### Calculating Label Probabilities\n",
        "Raw prediction data is stored as a list of dictionaries (one for each test case) within the model object `.results`. The `index` in the dataframe (generated by the example code block below) represents the position in the sequence that GPT-3 generated. The the token it selected is in the second column and its log probability is in the 3rd. In the `top_logprobs` column you can view the tokens GPT-3 selected among. The selected token has the lowest logprob in the `top_logprobs` cell.\n",
        "\n",
        "```\n",
        ">>> pd.DataFrame(few_shot_model.results[0][\"choices\"][0][\"logprobs\"])\n",
        "\n",
        "```\n",
        "\n",
        "We provide an internal function (i.e,. `extract_predictions()`) to calculate label probabilities. This returns probability estimates for each label. Given we weight our label tokens prior to classification (multi-class classification), GPT-3 usually picks among the labels specified. However, in cases where tokens were generated that are different than the labels presented, we offer an `'unknown_label'`.\n",
        "\n",
        "#### Outputting Predictions as Object\n",
        "Predictions can be extracted for additional purposes (e.g., model evaluation) using the `output_predictions()` method, and assigning the result to a new object (see examples below).\n",
        "\n",
        "#### Outputting Predictions to File\n",
        "Predictions can be output to a `csv` file using the `output_predictions()` function. **Importantly**, one must set the `output_file = True` and give the output file a name using the `output_file_name =` argument. Here are some examples:\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Examples: Outputting Predictions\n",
        "```python\n",
        "## Common use-cases\n",
        "# assigning prediction data to a new object then outputing file\n",
        ">>> test_predictions = few_shot_model.output_predictions()\n",
        ">>> test_predictions.to_csv(\"test-preds.csv\")\n",
        "# alternatively, using the output_file flag\n",
        ">>> few_shot_model.output_predictions(output_file = True, output_file_name = \"test-preds.csv\")\n",
        "```"
      ],
      "metadata": {
        "id": "tRq7gV-Z7A7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN: Output Predictions to CSV File\n",
        "few_shot_model.output_predictions(output_file = True, output_file_name = f'few-shot-{FEWSHOTK}-results.csv')"
      ],
      "metadata": {
        "id": "HGHTpdwuaf5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021dff8a-9353-435a-ee8f-cfe4775b836c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file output to: few-shot-5-results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Evaluating the Model\n",
        "---\n",
        "\n",
        "In a case where we are provided the *ground truth* test labels (e.g., the *'label'* column in the `raw_test_data` dataset), we provide the `evaluate_model()` function to calculate model evaluation metrics. \n",
        "\n",
        "**Note:** The `predicted` argument represents predictions and `actual` argument represents ground truth labels."
      ],
      "metadata": {
        "id": "kZhUO46-LvqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## RUN: Evaluate Model\n",
        "#test_predictions = few_shot_model.output_predictions()\n",
        "print(test_data['label'])\n",
        "test_predictions[\"predicted_label\"] = test_predictions[\"predicted_label\"].replace(few_shot_model.index_to_label)\n",
        "eval_metrics = evaluate_model(actual = test_data[\"label\"], predicted = test_predictions[\"predicted_label\"]) \n",
        "# Print Results\n",
        "eval_metrics"
      ],
      "metadata": {
        "id": "FZIGdAdrPKvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107e381d-1266-47e2-ea13-7cea8bbd6ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          agreeableness\n",
            "1          agreeableness\n",
            "2          agreeableness\n",
            "3           extraversion\n",
            "4           extraversion\n",
            "             ...        \n",
            "114        agreeableness\n",
            "115    conscientiousness\n",
            "116    conscientiousness\n",
            "117          neuroticism\n",
            "118          neuroticism\n",
            "Name: label, Length: 119, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall':            accuracy   macro avg  weighted avg\n",
              " precision  0.512605    0.579812      0.578634\n",
              " recall     0.512605    0.505756      0.512605\n",
              " f1-score   0.512605    0.503291      0.505618\n",
              " support    0.512605  119.000000    119.000000,\n",
              " 'by_label':             openness  conscientiousness  agreeableness  extraversion  \\\n",
              " precision   0.385965           0.625000       0.666667      0.571429   \n",
              " recall      0.880000           0.400000       0.347826      0.380952   \n",
              " f1-score    0.536585           0.487805       0.457143      0.457143   \n",
              " support    25.000000          25.000000      23.000000     21.000000   \n",
              " \n",
              "            neuroticism  \n",
              " precision     0.650000  \n",
              " recall        0.520000  \n",
              " f1-score      0.577778  \n",
              " support      25.000000  }"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    }
  ]
}