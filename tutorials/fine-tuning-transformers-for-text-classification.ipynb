{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMxrnS8VzUdw443K/D6lY6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shea-Fyffe/transforming-personality-scales/blob/main/tutorials/fine-tuning-transformers-for-text-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ZVjSGx2hzd"
      },
      "source": [
        "---\n",
        "# Fine-tuning Transformer Models for Text Classification of Big Five Items\n",
        "---\n",
        "This tutorial illistrates how to *fine-tune* (see [Lui et al., 2020](https://doi.org/10.1007/978-981-15-5573-2)) **Transformer** models to classify Big Five personality items. When applied for this specific purpose, fine-tuning involves training a classification model using a set of items with known Big Five trait labels. Afterwards, a fine-tuned model can be used to predict the Big Five trait of new items (or text).\n",
        "<br></br>\n",
        "While this notebook demonstrates how these models can be used for text classification of personality items (i.e., as an automated form of content analysis; [Short et al., 2018](https://doi.org/10.1146/annurev-orgpsych-032117-104622)), the same steps can be taken with other scale inventories or forms of text---merely by changing the training data and labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPlCRN53ULva"
      },
      "source": [
        "---\n",
        "## Setup\n",
        "---\n",
        "\n",
        "Below, we provide information regarding the libraries, functions, and classes used in this tutorial. *Text Blocks* (like this) will serve as informative sign posts. `Code Blocks` which have a black background will actually perform the commands. We recommend adding a *Scratch Code Cell* (**Ctrl+Alt+N**) for running commands interactively. \n",
        "<br></br>\n",
        "**Libraries and Modules**\n",
        "\n",
        "Colab comes with a large number of Python libraries pre-loaded. However, `Transformers` is not initially available in Colab. The `Transformers` library can be installed by using the code below. More information on the `Transformers` library can be seen [here](https://huggingface.co/transformers/quicktour.html).\n",
        "<br></br>\n",
        "**User-Defined Functions and Classes**\n",
        "\n",
        "Below we provide several classes and functions to help may the process a bit easier. For each function help text is provided and can be printed via `print(fun_name.__doc__)`. For example, to see documentation for the `fine_tune()` function:\n",
        "\n",
        "```\n",
        "print(fine_tune.__doc__)\n",
        "\n",
        "Output:\n",
        "\n",
        "  Fine-tune transformer model for text classification.\n",
        "\n",
        "  A wrapper function for fine-tuning a pre-trained transformer\n",
        "  from the popular transformers library. Abstracts away many of the steps\n",
        "  involved, such as loading a tokenizer and formatting data.\n",
        "  \n",
        "  Arguments\n",
        "  ---------\n",
        "  model: a string usually returned from ``get_model()``.\n",
        "  text: a list of text.\n",
        "  labels: a list of labels.\n",
        "  train_args: a dictionary of training arguments.\n",
        "  multi_label: a boolean specifying whether perform multi-label classification (False by default).\n",
        "  max_seq_len: a string determining how to pad text sequences ('longest' by default).\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  trainer : transformers.Trainer\n",
        "    a fine-tuned transformer model.\n",
        "  tokenizer : transformers.tokenizer\n",
        "    the tokenizer of the fine-tuned model.\n",
        "\n",
        "```\n",
        "This provides the arguments that can be modified to customize the fine-tuning process.\n",
        "<br></br>\n",
        "**Using a GPU**\n",
        "\n",
        "To speed things up you can use a *GPU* (*optional*). First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "You can confirm that you have an active GPU by using the following command:\n",
        "```\n",
        "# check using a command line interface\n",
        "!nvidia-smi\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7S6aRPS_w63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb10398-242b-4cac-e758-bd54b6536378"
      },
      "source": [
        "#@title Install libraries\n",
        "## Uncomment command below to install Transformers\n",
        "! pip install transformers\n",
        "! pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 82.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 96.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na3GNOWWScm0"
      },
      "source": [
        "#@title Import libraries and modules\n",
        "# load relevant modules from transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "\n",
        "# data libraries\n",
        "from torch.utils.data import Dataset # for formatting data before training\n",
        "import pandas as pd # for importing and exporting data\n",
        "\n",
        "# util libraries\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from google.colab import drive # optional for getting data\n",
        "from typing import Dict, List, Tuple # for type hinting\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import gc\n",
        "import warnings\n",
        "import requests\n",
        "from io import StringIO"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkXTg-LmUAkH"
      },
      "source": [
        "### Functions and Classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyQQt1yuCi2b",
        "cellView": "form"
      },
      "source": [
        "#@title Data-related functions\n",
        "# Custom data class\n",
        "class TextClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "# Import data function\n",
        "def import_data(path: str, text_col: str = 'text', label_col: str = None, enc: str = 'latin1'):\n",
        "    \"\"\"\n",
        "    Import a text data from a csv file.\n",
        "\n",
        "    A wrapper function around pandas.read_csv. Includes URL support.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    path: a string indicating a local csv file path or url.\n",
        "    text_col: a string indicating the name of column in csv containing text ('text' by default).\n",
        "    label_col: a string indicating the name of column in csv containing text labels ('label' by default).\n",
        "    enc: a string indicating csv file encoding ('latin1' by default).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "      a list of text.\n",
        "    List[str]\n",
        "      a list of labels.\n",
        "    pandas.DataFrame\n",
        "      the raw data.\n",
        "    \"\"\"\n",
        "    if (path.startswith(\"http\")):\n",
        "        res = requests.get(path,\n",
        "                           headers= {'User-Agent': 'Mozilla/5.0',\n",
        "                                     \"X-Requested-With\": \"XMLHttpRequest\"})\n",
        "        path = StringIO(res.text)\n",
        "    df = pd.read_csv(path, encoding = enc)\n",
        "    \n",
        "    if label_col is None:\n",
        "      return df[text_col].tolist(), df\n",
        "    return df[text_col].tolist(), df[label_col].tolist(), df\n",
        "\n",
        "# Format output data function\n",
        "def format_output_data(raw_outputs, test_case_ids = None, label_values = None, output_probabilities: bool = True,\n",
        "                       output_predicted_label: bool = True):\n",
        "    \"\"\"\n",
        "    Format model predictions to DataFrame.\n",
        "\n",
        "    A helper function that formats classification predictions taken from\n",
        "    ``transformers.Trainer.predict()`` into various outputs.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    raw_outputs: a numpy.ndarray of predictions from ``transformers.Trainer.predict()``.\n",
        "    test_case_ids: a list of test case ids (None by default).\n",
        "    label_values: a list of *unique ordered* labels (None by default).\n",
        "    output_probabilities: A boolean specifying whether to convert logit predictions to probabilities (True by default).\n",
        "    output_predicted_label: A boolean whether to append a 'predicted' column with the most likely label (True by default).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "      a dataset of predicted values.\n",
        "    \"\"\"\n",
        "    out_df = pd.DataFrame(raw_outputs)\n",
        "\n",
        "    if output_probabilities:\n",
        "        out_df = softmax(out_df, axis=1)\n",
        "    \n",
        "    if label_values is not None:\n",
        "        out_df.columns = label_values\n",
        "\n",
        "    if output_predicted_label:\n",
        "        out_df['predicted'] = out_df.idxmax(axis = 1)\n",
        "    \n",
        "    if test_case_ids is not None:\n",
        "        out_df.insert(0, 'id', test_case_ids)\n",
        "    return out_df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21aZOBc9Pvh"
      },
      "source": [
        "#@title Model-related functions\n",
        "# Custom fine-tuning function\n",
        "def fine_tune(model, text, labels, train_args, multi_label: bool = False, max_seq_len: str = 'longest', **kwargs):\n",
        "    \"\"\"\n",
        "    Fine-tune transformer model for text classification.\n",
        "  \n",
        "    A wrapper function for fine-tuning a pre-trained transformer\n",
        "    from the popular transformers library. Abstracts away many of the steps\n",
        "    involved, such as loading a tokenizer and formatting data.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    model: a string usually returned from ``get_model()``.\n",
        "    text: a list of text.\n",
        "    labels: a list of labels.\n",
        "    train_args: a dictionary of training arguments.\n",
        "    multi_label: a boolean specifying whether perform multi-label classification (False by default).\n",
        "    max_seq_len: a string determining how to pad text sequences ('longest' by default).\n",
        "    kwargs: additional keyword arguments to pass to ``Trainer.__init__``.\n",
        "  \n",
        "    Returns\n",
        "    -------\n",
        "    trainer : transformers.Trainer\n",
        "      a fine-tuned transformer model.\n",
        "    tokenizer : transformers.tokenizer\n",
        "      the tokenizer of the fine-tuned model.\n",
        "    \"\"\"\n",
        "    _, model_name = get_model(model)\n",
        "  \n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  \n",
        "    train_labels_indx, lab_to_id, num_labs = map_labels_to_keys(labels)\n",
        "    \n",
        "    if max_seq_len == 'longest':\n",
        "      train_encodings = tokenizer(text, truncation=True, padding=True)\n",
        "    else:\n",
        "      train_encodings = tokenizer(text, padding='max_len', max_length=max_seq_len)\n",
        "  \n",
        "    train_dataset = TextClassificationDataset(train_encodings, train_labels_indx)\n",
        "      \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name, num_labels=num_labs, label2id = lab_to_id\n",
        "        )\n",
        "    # will not preform multi_label_classification is number of labels is 2 (or fewer)\n",
        "    if multi_label and num_labs > 2:\n",
        "      model.problem_type = \"multi_label_classification\"\n",
        "    \n",
        "    # initialize Trainer class\n",
        "    trainer = Trainer(model=model,\n",
        "        args = training_args,\n",
        "        train_dataset = train_dataset,\n",
        "        **kwargs\n",
        "      )\n",
        "   \n",
        "    # train model\n",
        "    trainer.train()\n",
        "\n",
        "    # add tokenizer to use on the testing set\n",
        "    trainer.tokenizer = tokenizer\n",
        "\n",
        "    return trainer\n",
        "\n",
        "# Get model for simple transformers\n",
        "def get_model(model_type: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Get pre-trained transformer model.\n",
        "    \n",
        "    A helper function that looks up pre-trained model given model type. If model\n",
        "    is *not* found in lookup will ouput string used as input.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    model_type: a string indicating model type name (e.g., 'bart', 'bert', 'deberta', 'xlnet')\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    model_name : tuple(str, str)\n",
        "      a tuple of the model type and specific model name.\n",
        "      \n",
        "    See Also\n",
        "    --------\n",
        "    See https://huggingface.co/models for the complete repository of usable transformer models      \n",
        "    \"\"\"\n",
        "    model_dict = {\n",
        "    'albert': (\"albert\", \"albert-xlarge-v2\"),\n",
        "    'bart': (\"bart\", \"facebook/bart-large\"),\n",
        "    'bert': (\"bert\", \"bert-base-cased\"),\n",
        "    'deberta': (\"debertav2\", \"microsoft/deberta-v3-large\"),\n",
        "    'distilbert': (\"distilbert\", \"distilbert-base-cased-distilled-squad\"),\n",
        "    'distilroberta': (\"roberta\", \"cross-encoder/stsb-distilroberta-base\"),\n",
        "    'electra': (\"electra\", \"cross-encoder/ms-marco-electra-base\"),\n",
        "    'roberta': (\"roberta\", \"roberta-large\"),\n",
        "    'xlnet': (\"xlnet\", \"xlnet-large-cased\"),\n",
        "    'xmlroberta': (\"xmlroberta\", \"xlm-roberta-large\"),\n",
        "    }\n",
        "    # if model is not found will try model_type as model_name\n",
        "    model_name = model_dict.get(model_type, (model_type, model_type))\n",
        "    # returns a Tuple  \n",
        "    return model_name\n",
        "  \n",
        "# Compute evaluation metrics\n",
        "def evaluate_model(actual: List[str], predicted: List[str], label_values = None, **kwargs):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics on test data (given labels are available).\n",
        "\n",
        "    A helper function that returns model evaluation metrics. \n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    actual: list of actual labels.\n",
        "    predicted: list of predicted labels.\n",
        "    label_values: a list of *unique ordered* labels (None by default).\n",
        "    kwargs: additional keyword arguments to pass to ``sklearn.metrics.classification_report()``.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "      summary of the precision, recall, F1 score for each class\n",
        "    \"\"\"\n",
        "    if label_values is not None:\n",
        "        kwargs.update({'target_names': label_values})\n",
        "    else:\n",
        "        kwargs.update({'target_names': list(dict.fromkeys(actual))})\n",
        "        \n",
        "    res = classification_report(y_true = actual, y_pred = predicted, output_dict = True, **kwargs)\n",
        "\n",
        "    class_level = {k: res.get(k, None) for k in res.keys() if k in kwargs['target_names']}\n",
        "    overall = {k: res.get(k, None)for k in res.keys() if k not in kwargs['target_names']}\n",
        "    return {'overall' : pd.DataFrame(overall), 'by_label': pd.DataFrame(class_level)}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTOCF_TI7LoI"
      },
      "source": [
        "#@title Utility functions\n",
        "# Map labels to keys\n",
        "def map_labels_to_keys(labels: List[str], sort_labels: bool = True):\n",
        "    \"\"\"\n",
        "    Map text labels to integers.\n",
        "    \n",
        "    This function maps a list of strings to integers.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    labels: a list of labels\n",
        "    sort_labels: a boolean specifying if labels should be sorted alphabetically before recoding (True by default)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "      a list of labels.\n",
        "    dict{str : int}\n",
        "      a dictionary where labels are keys and mapped int are values.\n",
        "    int\n",
        "      the number of class labels.\n",
        "    \"\"\"\n",
        "    k = list(dict.fromkeys(labels))\n",
        "    if sort_labels:\n",
        "      k.sort()\n",
        "    labels_to_id = {k[i] : int(i) for i in range(0, len(k))}\n",
        "    labels_out = []\n",
        "    for j in labels:\n",
        "      labels_out.append(labels_to_id[j])\n",
        "    return labels_out, labels_to_id, len(k)\n",
        "\n",
        "# Helper to return labels from trained model\n",
        "def get_labels(trained_model):\n",
        "    \"\"\"\n",
        "    Return list of class labels from a model returned by `Trainer.train()`\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    trained_model: a trained transformer model of class Trainer.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "      a list of labels.\n",
        "    \"\"\"\n",
        "    return trained_model.model.config.label2id\n",
        "    \n",
        "# Helper to check for GPU device and garbage collect\n",
        "def get_gpu ():\n",
        "    \"\"\"\n",
        "    Check if CUDA compatible GPU is available.\n",
        "\n",
        "    To manually check if you are able to use a GPU environment in Colab click\n",
        "    the `Runtime` menu above, then select `Change Runtime Type`, the pick \"GPU\"\n",
        "    for the `Hardware Accelerator` dropdown.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "      number of current CUDA GPU device. If -1, no was found. \n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "      return torch.cuda.current_device()\n",
        "    else:\n",
        "      return -1\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdULdNEfUYb1"
      },
      "source": [
        "---\n",
        "## Selecting Model and Hyper-Parameters\n",
        "---\n",
        "We define our variables for purposes described in our research manuscript. However, we encourage researchers and practitioners to try out alternative models (by manually overriding `transformer_model`). In addition, we wanted to minimize the tuning hyper-parameters during training as the aim of this research is to highlight Transformers in a baseline sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8tlBiCW5mBy"
      },
      "source": [
        "#@title Select pre-trained transformer model\n",
        "transformer_model = \"deberta\" #@param [\"deberta\", \"albert\", \"bert\", \"bart\", \"distilbert\",\"distilroberta\", \"electra\", \"roberta\", \"xlnet\", \"xlmroberta\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GAQl22KulEr"
      },
      "source": [
        "#@title Define training hyper-parameters\n",
        "\n",
        "# length to pad items to (~each word is 1.15 sequence units)\n",
        "SEQ_LEN = 32\n",
        "\n",
        "# first we can initialized the ClassificationArguments object\n",
        "training_args = TrainingArguments(\n",
        "   num_train_epochs = 10,\n",
        "   learning_rate = 2e-5,\n",
        "   warmup_ratio = 0.10,\n",
        "   weight_decay = 0.01,\n",
        "   per_device_train_batch_size = 16,\n",
        "   seed = 42,\n",
        "   logging_strategy=\"epoch\", \n",
        "   output_dir = f\"{transformer_model}/outputs\",\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU5mojBFURyy"
      },
      "source": [
        "---\n",
        "## Uploading and Importing Data\n",
        "---\n",
        "\n",
        "**Uploading Data**\n",
        "\n",
        "While there are several ways to import data into Colab ([see here](https://colab.research.google.com/notebooks/io.ipynb)), the most intuitive way is to use the project's code repository url:\n",
        "\n",
        "```\n",
        "# Assign the online data repository to a url so it does not have to be repeated later\n",
        "repository_data_path = \"https://anonymous.4open.science/api/repo/transforming-personality-scales/file/data/text-classification/\"\n",
        "```\n",
        "\n",
        "As an alternative, you can also upload a local `.csv` file. You can do this by:\n",
        "- Visiting the project url above and clicking the `download file` button (top right in project repository)\n",
        "- Clicking the ***Files*** pane in Colab (the folder icon on the left in Colab)\n",
        "- Clicking the ***Upload to session storage*** icon (left-most icon in Colab)\n",
        "- Selecting the local data file you would like to use (e.g., `.csv`,`.tsv`)\n",
        "\n",
        "If using this method, the path to the file can be used. To locate the file path using the *Colab File Pane* (folder icon on the left-hand side). Generally, uploaded files will be in the `/content/` directory. Once the file is found, right click the file and select \"Copy path.\" This path can be pasted into the `import_data` function directly or assigned to an object that can be used later.\n",
        "\n",
        "```\n",
        "local_file_path = \"content/train-data.csv\"\n",
        "```\n",
        "</br>\n",
        "\n",
        "**Importing Data**\n",
        "\n",
        "To properly import the training data we must specify the file path, column name containing our items, and column name containing our labels. Then, the `import_data()` returns three objects:\n",
        "\n",
        "- a list (vector) of items\n",
        "- a list (vector) of labels\n",
        "- a copy of our training data\n",
        "\n",
        "```\n",
        "# Example using the url\n",
        "train_text, train_labels, train_raw_data = import_data(repository_data_path + 'train-data.csv', \"text\", \"label\")\n",
        "\n",
        "# Example using a local file path\n",
        "train_text, train_labels, train_raw_data = import_data(\"/\" + local_file_path, \"text\", \"label\")\n",
        "```\n",
        "\n",
        "The code above assigns these to objects names `train_text`, `train_labels` and `raw_data` respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M28uNo1ssSF"
      },
      "source": [
        "#### Importing the training and testing data\n",
        "\n",
        "We will now import the training and testing data, named---`train-data.csv` and `test-data.csv` respectively. These data can be found on our [GitHub repo](https://anonymous.4open.science/r/transforming-personality-scales/data/text-classification/train-data.csv) in the directory `data/text-classification/`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the online data repository to a url so it doesn't have to be repeated laterr\n",
        "repository_data_url = 'https://anonymous.4open.science/api/repo/transforming-personality-scales/file/data/text-classification/'\n",
        "\n",
        "# the import_data function will return a list of sentences, a list of labels, and the original dataset\n",
        "train_text, train_labels, raw_training_data = import_data(repository_data_url + 'train-data.csv', \"text\", \"label\")\n",
        "\n",
        "# the import_data function will return a list of sentences and the original dataset if label is left blank\n",
        "test_text, raw_test_data = import_data(repository_data_url + 'test-data.csv', \"text\")"
      ],
      "metadata": {
        "id": "vYmz5jdG_LWS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we show the first 10 items in the training set\n",
        "# ... and their corresponding labels\n",
        "for x,y in zip(train_text[:10], train_labels[:10]):\n",
        "    print(\"Item: %s | Label: %s\" %(x, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HznvjAPZD_P",
        "outputId": "2c50b10d-efef-4123-e53f-813be38057fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item: I rarely feel depressed. | Label: neuroticism\n",
            "Item: I always know what I am doing. | Label: conscientiousness\n",
            "Item: I do not put my mind on the task at hand. | Label: conscientiousness\n",
            "Item: I keep things tidy. | Label: conscientiousness\n",
            "Item: I laugh a lot. | Label: extraversion\n",
            "Item: I rarely get caught up in the excitement. | Label: extraversion\n",
            "Item: I am not a very enthusiastic person. | Label: extraversion\n",
            "Item: I see myself as a good leader. | Label: extraversion\n",
            "Item: I can talk others into doing things. | Label: extraversion\n",
            "Item: I do not have an assertive personality. | Label: extraversion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm6IMLaY-lu-"
      },
      "source": [
        "---\n",
        "## Training the Model\n",
        "---\n",
        "\n",
        "To clarify: *fine-tuning* is a specific type of training applied to models that have been pre-trained. This process allows the model to update its parameters to better align with our classification task.\n",
        "\n",
        "The `fine-tune()` function requires that we define four arguments. We provide a description of each and the (`object`) holding such data:\n",
        "- The model or type of transformer model (`transformer_model`)\n",
        "- Text or personality items (`train_text`)\n",
        "- Text or item class labels (`train_labels`)\n",
        "- The training hyper parameters (`trainings_args`) \n",
        "\n",
        "This results in a function call that looks like:\n",
        "\n",
        "```\n",
        "fine_tuned_model, tokenizer = fine_tune(model = transformer_model,\n",
        "                                        text = train_text,\n",
        "                                        labels = train_labels,\n",
        "                                        train_args = training_args)\n",
        "```\n",
        "\n",
        "There are several *optional* arguments, such as `max_seq_len` which determines how long text is truncated (discussed below). Additionally, there's the `multi_label` argument&mdash;by setting `multi_label` to `True` i.e., `fine_tune(..., multi_label = True)` one can train a model that will treat items as multi-dimensional, so items may belong to multiple classes at once.\n",
        "\n",
        "\n",
        "**Tokenizing**\n",
        "\n",
        "The `fine_tune()` function outputs the fine-tuned model (i.e., `fine_tuned_model`) and add model’s tokenizer to the object (i.e., `fine_tuned_model.tokenizer`). This step ensures both the testing and training items will be tokenized in the same way. Since we will not input the test data to the `fine_tune` function, the model's tokenizer object (i.e., `fine_tuned_model.tokenizer`) will be used right before predicting the class labels of the test items.\n",
        "\n",
        "The `fine_tuned_model.tokenizer()` function has several notable arguments&mdash;`truncation` and `padding`. While truncation is not relevant to our case (because personality items tend to be relatively short text documents), setting `truncation=True` ensures that any document longer than the specified sequence length is truncated. Setting `padding=True`, ensures that any document shorter than the specified sequence length is padded up to that point. Usually transformers default sequence length to 512 tokens; however, it is best practice to set it to a number that is roughly 150% of the words in the longest text document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_tmG_6v-3oC"
      },
      "source": [
        "# tune the model using the labeled personality items\n",
        "fine_tuned_model = fine_tune(transformer_model, train_text, train_labels, training_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldtRKgWMtGIP"
      },
      "source": [
        "---\n",
        "## Testing the Model\n",
        "---\n",
        "\n",
        "Since we've fined tuned the model, we can now use the `.predict()` method to predict the labels of new personality items as well as other types of text documents (e.g., survey responses, social media comments, and performance evaluations).\n",
        "\n",
        "After performing predictions on the test data, we can clean up the results with `format_output_data()`. By default the function will return multi-class probabilities and the most likely label, which is appended as a column named *'predicted'*. These options can be modified by setting the arguments `output_probabilities` and `output_predicted_label` to `False`. For example:\n",
        "\n",
        "```\n",
        "# output predicted label and logit values\n",
        "out_test_df = format_output_data(predictions, output_probabilities = False)\n",
        "\n",
        "# output probabilities but no predicted label\n",
        "out_test_df = format_output_data(predictions, output_predicted_label = False)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FTP0LlVsHol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2dfa5299-6348-4676-a1ab-834594946536"
      },
      "source": [
        "#@title Predict labels of the test items\n",
        "\n",
        "# pre-process the test data before prediction\n",
        "test_encodings = fine_tuned_model.tokenizer(test_text, truncation=True, padding=True)\n",
        "test_dataset = TextClassificationDataset(test_encodings)\n",
        "\n",
        "# predict the test set and return single label predictions and the raw logits\n",
        "predictions, _, _ = fine_tuned_model.predict(test_dataset)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 119\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqiII1y0uahz"
      },
      "source": [
        "#@title Format test predictions\n",
        "# we can format the output and save it, be sure to add label values\n",
        "out_test_df = format_output_data(predictions, label_values = get_labels(fine_tuned_model))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Evaluating the Model\n",
        "---\n",
        "\n",
        "In a case where we are provided the *ground truth* test labels (e.g., the *'label'* column in the `raw_test_data` dataset), we provide the `evaluate_model()` function to calculate model evaluation metrics. \n",
        "\n",
        "**Note:** The *'predicted'* column needs to be present in the `out_test_df` (or calculated manually) and then defined as `predicted =` argument."
      ],
      "metadata": {
        "id": "kZhUO46-LvqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model evaluation metrics\n",
        "eval_metrics = evaluate_model(actual = raw_test_data[\"label\"], predicted = out_test_df[\"predicted\"])\n",
        "\n",
        "# Print Results\n",
        "eval_metrics"
      ],
      "metadata": {
        "id": "FZIGdAdrPKvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b950d4c7-1e94-4740-b4e0-a46781036e30"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall':            accuracy   macro avg  weighted avg\n",
              " precision  0.823529    0.830026      0.833937\n",
              " recall     0.823529    0.824778      0.823529\n",
              " f1-score   0.823529    0.821486      0.823006\n",
              " support    0.823529  119.000000    119.000000,\n",
              " 'by_label':            agreeableness  extraversion   openness  neuroticism  \\\n",
              " precision           0.90      0.875000   0.850000     0.703704   \n",
              " recall              0.72      0.840000   0.739130     0.904762   \n",
              " f1-score            0.80      0.857143   0.790698     0.791667   \n",
              " support            25.00     25.000000  23.000000    21.000000   \n",
              " \n",
              "            conscientiousness  \n",
              " precision           0.821429  \n",
              " recall              0.920000  \n",
              " f1-score            0.867925  \n",
              " support            25.000000  }"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Saving predictions\n",
        "out_test_df.to_csv(f\"{transformer_model}-test-preds.csv\", index=False)"
      ],
      "metadata": {
        "id": "3xE84g78XtcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWAyf4Rw1TGg"
      },
      "source": [
        "---\n",
        "### Saving the Model\n",
        "---\n",
        "Fine-tuned models can also be saved for further training or prediction. Since we utilized a testing set, the model trained here did not get to train on all the items collected. Thus, after saving the model, we perform some additional training using the testing data. For example:\n",
        "\n",
        "```\n",
        "# Save the fine tuned model\n",
        "fine_tuned_model.save_model(\"fine-tuned-big5-personality-model\")\n",
        "\n",
        "# Then re-run the fine_tune function changing the model path, training text, and labels\n",
        "really_fine_tuned_model, tokenizer = fine_tune(\"fine-tuned-big5-personality-model\",\n",
        "    test_text, raw_test_data[\"label\"], training_args)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIdA0Ibs1fOB"
      },
      "source": [
        "#@title Save fine-tuned model\n",
        "# Uncomment the line below to save the fine-tuned model for later use\n",
        "# fine_tuned_model.save_model(\"fine-tuned-big5-personality-model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CgVMp7OL7Pw"
      },
      "source": [
        "---\n",
        "### Classifying New Examples\n",
        "---\n",
        "\n",
        "```\n",
        "# Load Python libraries\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Import model to classify new items\n",
        "big5_model = AutoModel.from_pretrained(\"fine-tuned-big5-personality-model\")\n",
        "big5_tokenizer = AutoTokenizer.from_pretrained(\"fine-tuned-big5-personality-model\")\n",
        "\n",
        "# Create classification pipeline\n",
        "classify_items = pipeline(\"text-classification\", model=big5_model, tokenizer=big5_tokenizer)\n",
        "\n",
        "# Import or generate items to classify (taken from openpsychometrics.org)\n",
        "new_items = [\"I put family first.\",  \n",
        "             \"When other people are arguing, I leave the room.\", \n",
        "             \"I have a bland facial expression when I talk to people.\", \n",
        "             \"Does your heart ever thump in your ears so that you cannot sleep?\"]\n",
        "\n",
        "# Classify items to the Big Five factors\n",
        "results = classify_items(new_items)\n",
        "```\n"
      ]
    }
  ]
}