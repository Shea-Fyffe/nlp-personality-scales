{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine-tuning-transformers-for-text-classification",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOqxLLe4R0qQ96XlLzQDusA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shea-Fyffe/transforming-personality-scales/blob/main/vignettes/fine_tuning_transformers_for_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ZVjSGx2hzd"
      },
      "source": [
        "# Fine-tuning Transformer Models for Text Classification\n",
        "This colab is written in **Python** to illistrate the process of *fine-tuning* (see [Lui et al., 2020](https://doi.org/10.1007/978-981-15-5573-2)) state-of-the-art **Transformer** models to classify personality items. In this context the fine-tuning process involves training models with a relatively small amount of items with known trait labels. While this notebook demonstrates how these models can be used for text classification of personality items (i.e., as an automated form of content analysis; [Short et al., 2018](https://doi.org/10.1146/annurev-orgpsych-032117-104622)), the same steps can be taken with other scale inventories or forms of text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPlCRN53ULva"
      },
      "source": [
        "### Libraries\n",
        "\n",
        "Colab comes with a large number of Python libraries pre-loaded. However, `Transformers` is not initially available in Colab. The `Transformers` library can be installed by using the code below.\n",
        "\n",
        "More information on the `Transformers` library can be seen [here](https://huggingface.co/transformers/quicktour.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7S6aRPS_w63"
      },
      "source": [
        "#@title Installing Transformers\n",
        "\n",
        "## Uncomment command below to install Transformers\n",
        "! pip install transformers\n",
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A25eSs8QUkS8"
      },
      "source": [
        "# load text classification modules from simpletransformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "\n",
        "# data libraries\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "# util libraries\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive # optional for getting data\n",
        "from typing import Dict, List # for type hinting\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import gc\n",
        "import warnings\n",
        "import requests\n",
        "from io import StringIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0eCZR2ngddV"
      },
      "source": [
        "### Using a GPU\n",
        "To speed things up you can use a *GPU* (*optional*).\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, confirm that you can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXnDmXR7RDr2"
      },
      "source": [
        "# A helper function to check for a GPU\n",
        "# To check if you are able to use a GPU environment in Colab click the `Runtime` menu above, then select `Change Runtime Type`, the pick \"GPU\" for the `Hardware Accelerator` dropdown\n",
        "def get_gpu ():\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return torch.cuda.current_device()\n",
        "  else:\n",
        "    return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE95PDPffa4-"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkXTg-LmUAkH"
      },
      "source": [
        "### Functions and Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyQQt1yuCi2b"
      },
      "source": [
        "#@title Data Class\n",
        "class TextClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ekBE-p49KLC"
      },
      "source": [
        "#@title Fine-tuning function\n",
        "def fine_tune(model, text, labels, train_args, multi_label: bool = False,\n",
        "              time_stamp_out_dir: bool = True, max_seq_len: str = 'longest'):\n",
        "  \"\"\"Fine-tune a Transformers model for text classification\n",
        "  \n",
        "  Args:\n",
        "    model: a valid string representing the model_type\n",
        "    text: a list of sentences to use for fine-tuning\n",
        "    labels: a list of labels\n",
        "    train_args: dictionary of training arguments\n",
        "    multi_label: A boolean (True/False). If True (False by default) will perform multi-label classification \n",
        "    time_stamp_out_dir: Perform multi-label classification (optional)\n",
        "    max_seq_len: string determining how to pad text sequences (optional)\n",
        "  \"\"\"\n",
        "  if time_stamp_out_dir:\n",
        "    _, new_out_dir = update_directories(train_args.output_dir)\n",
        "    train_args.output_dir = new_out_dir\n",
        "\n",
        "  _, model_name = get_model(model)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  train_labels_indx, lab_to_id, num_labs = map_labels_to_keys(labels)\n",
        "  \n",
        "  if max_seq_len == 'longest':\n",
        "    train_encodings = tokenizer(text, truncation=True, padding=True)\n",
        "  else:\n",
        "    train_encodings = tokenizer(text, padding='max_len', max_length=max_seq_len)\n",
        "\n",
        "  train_dataset = TextClassificationDataset(train_encodings, train_labels_indx)\n",
        "    \n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\n",
        "      model_name, num_labels=num_labs, label2id = lab_to_id\n",
        "      )\n",
        "  \n",
        "  if multi_label:\n",
        "    model.problem_type = \"multi_label_classification\"\n",
        "\n",
        "  trainer = Trainer(model=model,\n",
        "      args = training_args,\n",
        "      train_dataset = train_dataset\n",
        "    )\n",
        " \n",
        "  trainer.train()\n",
        "    \n",
        "  return trainer, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21aZOBc9Pvh"
      },
      "source": [
        "#@title Load user-defined utility functions\n",
        "\n",
        "# Import Data function\n",
        "def import_data(path: str, text_col, label_col = None, enc = 'latin1'):\n",
        "  \"\"\"Import a CSV of sentences\n",
        "  \n",
        "  Args:\n",
        "    path: A csv file path or url pointing at CSV file\n",
        "    text_col: Name of column in csv containing sentences\n",
        "    label_col: Name of column containing labels\n",
        "    enc: File encoding to be used (optional)\n",
        "  \"\"\"\n",
        "  if (path.startswith(\"http\")):\n",
        "      res = requests.get(path,\n",
        "                         headers= {'User-Agent': 'Mozilla/5.0',\n",
        "                                   \"X-Requested-With\": \"XMLHttpRequest\"})\n",
        "      path = StringIO(res.text)\n",
        "  df = pd.read_csv(path, encoding = enc)\n",
        "  \n",
        "  if label_col is None:\n",
        "    return df[text_col].tolist(), df\n",
        "  return df[text_col].tolist(), df[label_col].tolist(), df\n",
        "\n",
        "# Map labels to keys\n",
        "def map_labels_to_keys(labels: str, sort_labels = True):\n",
        "  \"\"\"Map text labels to integers\n",
        "  \n",
        "  Args:\n",
        "    labels: a list/vector of text labels\n",
        "    sort_labels: Sort labels alphabetically before recoding (optional)\n",
        "  \"\"\"\n",
        "  k = list(dict.fromkeys(labels))\n",
        "  if sort_labels:\n",
        "    k.sort()\n",
        "  labels_to_id = {k[i] : int(i) for i in range(0, len(k))}\n",
        "  labels_out = []\n",
        "  for j in labels:\n",
        "    labels_out.append(labels_to_id[j])\n",
        "  return labels_out, labels_to_id, len(k)\n",
        "\n",
        "# Update model directories\n",
        "def update_directories(model_output_dir: str) -> str:\n",
        "    file_time = datetime.datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
        "    model_output_dir = f'{model_output_dir}-{file_time}/'\n",
        "    out_file = f\"{model_output_dir}/{file_time}_results.csv\"\n",
        "    return out_file, model_output_dir\n",
        "\n",
        "# Get model for simple transformers\n",
        "def get_model(model_type: str) -> List[str]:\n",
        "    model_dict = {\n",
        "        'albert': \"albert-xlarge-v2\",\n",
        "        'bart': \"facebook/bart-large\",\n",
        "        'bert': \"bert-base-cased\",\n",
        "        'deberta': [\"debertav2\", \"microsoft/deberta-v3-large\"],\n",
        "        'distilbert': \"distilbert-base-cased-distilled-squad\",\n",
        "        'distilroberta': ['roberta', \"cross-encoder/stsb-distilroberta-base\"],\n",
        "        'electra': \"cross-encoder/ms-marco-electra-base\",\n",
        "        'roberta': \"roberta-large\",\n",
        "        'xlnet': \"xlnet-large-cased\",\n",
        "        'xmlroberta': \"xlm-roberta-large\",\n",
        "    }\n",
        "    model_name = model_dict.get(model_type, [model_type, model_type])\n",
        "    if isinstance(model_name, str):\n",
        "        model_name = [model_type, model_name]\n",
        "    return model_name\n",
        "\n",
        "# Format output data function\n",
        "def format_output_data(raw_outputs, test_case_ids = None, label_values = None, output_probabilities: bool = True,\n",
        "                       output_predicted_label: bool = True):\n",
        "  \"\"\"Format test data to be output to CSV\n",
        "  \n",
        "  Args:\n",
        "    raw_outputs: The raw_outputs from transformers model.predict()\n",
        "    test_case_ids: A list of test case ids (optional)\n",
        "    label_values: A list of *unique ordered* labels (optional)\n",
        "    output_probabilities: A boolean (True/False). If True (the default) will convert logit predictions to probabilities\n",
        "    output_predicted_label: A boolean (True/False). If True (the default) will append a 'predicted' column as most likely label  \n",
        "  \"\"\"\n",
        "  \n",
        "  out_df = pd.DataFrame(raw_outputs)\n",
        "\n",
        "  if output_probabilities:\n",
        "      out_df = softmax(out_df, axis=1)\n",
        "  \n",
        "  if output_predicted_label:\n",
        "      out_df['predicted'] = np.argmax(out_df, axis=1)\n",
        "  \n",
        "  if label_values is not None:\n",
        "      out_df.columns = label_values\n",
        "  \n",
        "  if test_case_ids is not None:\n",
        "      out_df.insert(0, 'id', test_case_ids)\n",
        "\n",
        "  return out_df\n",
        "  \n",
        "# compute evaluation metrics\n",
        "def evaluate_model(actual: List, predicted: List, label_values = None, **kwargs):\n",
        "  \"\"\"Calculate evaluation metrics on test labels\n",
        "  \n",
        "  Args:\n",
        "    actual: list of actual labels\n",
        "    predicted: list of predicted labels\n",
        "    label_values: A *unique ordered* list of labels (optional)\n",
        "    kwargs: Additional arguments to pass to sklearn.metrics.classification_report\n",
        "  \"\"\"\n",
        "\n",
        "  if label_values is not None:\n",
        "      kwargs.update({'target_names': label_values})\n",
        "  else:\n",
        "      kwargs.update({'target_names': list(dict.fromkeys(actual))})\n",
        "      \n",
        "  return classification_report(y_true = actual, y_pred = predicted, **kwargs)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdULdNEfUYb1"
      },
      "source": [
        "### Selecting Model and Hyper-Parameters\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We define our variables for purposes described in our research manuscript. However, we encourage researchers and practitioners to try out alternative models (by manually overriding `transformer_model`). In addition, we wanted to minimize the tuning hyper-parameters during training as the aim of this research is to highlight Transformers in a baseline sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8tlBiCW5mBy"
      },
      "source": [
        "#@title Define model to train\n",
        "transformer_model = \"deberta\" #@param [\"deberta\", \"albert\", \"bert\", \"bart\", \"distilbert\",\"distilroberta\", \"electra\", \"roberta\", \"xlnet\", \"xlmroberta\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GAQl22KulEr"
      },
      "source": [
        "#@title Define training hyper-parameters\n",
        "\n",
        "# length to pad items to (~each word is 1.15 sequence units)\n",
        "SEQ_LEN = 32\n",
        "\n",
        "# first we can initialized the ClassificationArguments object\n",
        "training_args = TrainingArguments(\n",
        "   num_train_epochs = 10,\n",
        "   learning_rate = 2e-5,\n",
        "   warmup_ratio = 0.10,\n",
        "   weight_decay = 0.01,\n",
        "   per_device_train_batch_size = 16,\n",
        "   seed = 42,\n",
        "   load_best_model_at_end=True,\n",
        "   evaluation_strategy=\"steps\", \n",
        "   output_dir = f\"{transformer_model}/outputs\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU5mojBFURyy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Fine-tuning A Transformer Model\n",
        "\n",
        "\n",
        "---\n",
        "This example demonstrates the fine-tuning process for the purpose of classifying personality items into their respective content domains.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOpPwcYvTvc"
      },
      "source": [
        "### Importing and formatting Training Data\n",
        "\n",
        "\n",
        "While there are several ways to import data into Colab ([see here](https://colab.research.google.com/notebooks/io.ipynb)), the most intuitive way is to use the project's code repository url:\n",
        "\n",
        "```\n",
        "# Assign the online data repository to a url so it does not have to be repeated later\n",
        "repository_data_url = \"https://anonymous.4open.science/api/repo/transforming-personality-scales/file/data/text-classification/\"\n",
        "\n",
        "# the import_data function will return a list of sentences, a list of labels, and the original dataset\n",
        "train_text, train_labels, train_raw_data = import_data(repository_data_url + 'train-data.csv', \"text\", \"label\")\n",
        "```\n",
        "\n",
        "\n",
        "You can also upload a local `.csv` file. You can do this by:\n",
        "- Visiting the project url above and clicking the `download file` button (top right in project repository)\n",
        "- Clicking the ***Files*** pane in Colab (the folder icon on the left in Colab)\n",
        "- Clicking the ***Upload to session storage*** icon (left-most icon in Colab)\n",
        "- Selecting the local data file you would like to use (e.g., `.csv`,`.tsv`)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the online data repository to a url so it doesn't have to be repeated laterr\n",
        "repository_data_url = 'https://anonymous.4open.science/api/repo/transforming-personality-scales/file/data/text-classification/'"
      ],
      "metadata": {
        "id": "vYmz5jdG_LWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M28uNo1ssSF"
      },
      "source": [
        "For this example, I've imported a file named `train-data.csv` (found on our [GitHub repo](https://anonymous.4open.science/r/transforming-personality-scales/data/text-classification/train-data.csv) in the directory `data/text-classification/`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD0E9EpLr3-V"
      },
      "source": [
        "#@title Importing training dataset\n",
        "# the import_data function will return a list of sentences, a list of labels, and the original dataset\n",
        "train_text, train_labels, raw_training_data = import_data(repository_data_url + 'train-data.csv', \"text\", \"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob7mKIM_8Dpz"
      },
      "source": [
        "To properly import the training data we must specify the file path, column name containing our items, and column name containing our labels. Then, the `import_data()` returns three objects:\n",
        "\n",
        "- a list (vector) of items\n",
        "- a list (vector) of labels\n",
        "- a copy of our training data\n",
        "\n",
        "The code above assigns these to objects names `train_text`, `train_labels` and `raw_data` respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm6IMLaY-lu-"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "---\n",
        "\n",
        "Our fine-tune function only requires that we define the `Transformer model` we would like to use, as well as `input a vector of text` (i.e., personality items in this example), the `trait labels`, and the `training arguments` (which we defined in the **Selecting Model and Hyper-Parameters** section of this tutorial). There are optional arguments, such as time-stamping the output directory, which would be a good ideal if training mulitple models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_tmG_6v-3oC"
      },
      "source": [
        "# tune the model using the labeled personality items\n",
        "fine_tuned_model, tokenizer = fine_tune(transformer_model, train_text, train_labels, training_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldtRKgWMtGIP"
      },
      "source": [
        "### Testing the Model\n",
        "\n",
        "---\n",
        "\n",
        "Since we've fined tuned the model we can use the `.predict()` method to predict the labels of new text---for example---personality items, survey responses, and even performance evaluations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC4VyJrCsxQl"
      },
      "source": [
        "#### Import the test data\n",
        "First, we must import the test data (`test-data.csv`), making sure we only specify the `path (url)` and `text_col` in the `import_data()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shc7rJxisSOZ"
      },
      "source": [
        "#@title Importing testing dataset\n",
        "# the import_data function will return a list of sentences and the original dataset if label is left blank\n",
        "test_text, raw_test_data = import_data(repository_data_url + 'test-data.csv', \"text\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Roz1kCifzq"
      },
      "source": [
        "# pre-process the test data before prediction\n",
        "test_encodings = tokenizer(test_text, truncation=True, padding=True)\n",
        "test_dataset = TextClassificationDataset(test_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrMpanHluUfx"
      },
      "source": [
        "#### Predict labels of the test items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FTP0LlVsHol"
      },
      "source": [
        "# predict the test set and return single label predictions and the raw logits\n",
        "predictions, _, _ = fine_tuned_model.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default the `format_output_data` function will return multi-class probabilities and the most likely label, which is appended as a column named *'predicted'*. These options can be modified by setting the arguments `output_probabilities` and `output_predicted_label` to `False`. For example:\n",
        "\n",
        "```\n",
        "# output predicted label and logit values\n",
        "out_test_df = format_output_data(predictions, output_probabilities = False)\n",
        "\n",
        "# output probabilities but no predicted label\n",
        "out_test_df = format_output_data(predictions, output_predicted_label = False)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "tOooERhwBF5h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqiII1y0uahz"
      },
      "source": [
        "# we can format the output and save it\n",
        "out_test_df = format_output_data(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdmSmmGAvhDr"
      },
      "source": [
        "# save results\n",
        "out_test_df.to_csv(f\"{transformer_model}-test-preds.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Model\n",
        "\n",
        "---\n",
        "\n",
        "In a case where we are provided the *ground truth* test labels (e.g., the *'label'* column in the `raw_test_data` dataset), we provide the `evaluate_model()` function to calculate model evaluation metrics (see ***Load user-defined utility functions*** code block for function documentation).\n",
        "\n",
        "**Note:** The *'predicted'* column needs to be present in the `out_test_df` (or calculated manually) and then defined as `predicted =` argument."
      ],
      "metadata": {
        "id": "kZhUO46-LvqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model evaluation metrics\n",
        "eval_metrics = evaluate_model(actual = raw_test_data[\"label\"], predicted = out_test_df[\"predicted\"])"
      ],
      "metadata": {
        "id": "FZIGdAdrPKvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWAyf4Rw1TGg"
      },
      "source": [
        "### Saving the model\n",
        "fine-tuned models can also be saved and used for down-stream tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIdA0Ibs1fOB"
      },
      "source": [
        "# Uncomment the line below to save the fine-tuned model for later use\n",
        "# fine_tuned_model.save_model(f\"{transformer_model}-fine-tuned-big5-personality\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}